{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68fbd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def efficient_net(input_tensor, resolution, depth, width, num_classes, dropout_rate=0.2, include_top=True):\n",
    "    def round_filters(filters, width_multiplier, divisor):\n",
    "        filters *= width_multiplier\n",
    "        new_filters = int(filters + divisor / 2) // divisor * divisor\n",
    "        new_filters = max(divisor, new_filters)\n",
    "        if new_filters < 0.9 * filters:\n",
    "            new_filters += divisor\n",
    "        return int(new_filters)\n",
    "\n",
    "    def round_repeats(repeats, depth_multiplier):\n",
    "        return int(depth_multiplier * repeats)\n",
    "\n",
    "    def swish(x):\n",
    "        return x * tf.nn.sigmoid(x)\n",
    "\n",
    "    def fused_mbconv_block(x, expand_filters, out_filters, strides):\n",
    "        y = tf.keras.layers.Conv2D(expand_filters, kernel_size=1, padding='same', use_bias=False)(x)\n",
    "        y = tf.keras.layers.BatchNormalization(axis=3)(y)\n",
    "        y = swish(y)\n",
    "\n",
    "        y = tf.keras.layers.DepthwiseConv2D(kernel_size=3, strides=strides, padding='same', use_bias=False)(y)\n",
    "        y = tf.keras.layers.BatchNormalization(axis=3)(y)\n",
    "        y = swish(y)\n",
    "\n",
    "        y = tf.keras.layers.Conv2D(out_filters, kernel_size=1, padding='same', use_bias=False)(y)\n",
    "        y = tf.keras.layers.BatchNormalization(axis=3)(y)\n",
    "\n",
    "        if strides == 1 and x.shape[-1] == out_filters:\n",
    "            y = tf.keras.layers.Add()([x, y])\n",
    "\n",
    "        return y\n",
    "\n",
    "    def mbconv_block(x, expand_filters, out_filters, strides):\n",
    "        y = tf.keras.layers.Conv2D(expand_filters, kernel_size=1, padding='same', use_bias=False)(x)\n",
    "        y = tf.keras.layers.BatchNormalization(axis=3)(y)\n",
    "        y = swish(y)\n",
    "\n",
    "        y = tf.keras.layers.DepthwiseConv2D(kernel_size=3, strides=strides, padding='same', use_bias=False)(y)\n",
    "        y = tf.keras.layers.BatchNormalization(axis=3)(y)\n",
    "        y = swish(y)\n",
    "\n",
    "        y = tf.keras.layers.Conv2D(out_filters, kernel_size=1, padding='same', use_bias=False)(y)\n",
    "        y = tf.keras.layers.BatchNormalization(axis=3)(y)\n",
    "\n",
    "        if strides == 1 and x.shape[-1] == out_filters:\n",
    "            y = tf.keras.layers.Add()([x, y])\n",
    "\n",
    "        return y\n",
    "\n",
    "    def cbam_block(x):\n",
    "        channels = x.shape[-1]\n",
    "        y = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        y = tf.keras.layers.Reshape((1, 1, channels))(y)\n",
    "        y = tf.keras.layers.Dense(channels // 4, activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(y)\n",
    "        y = tf.keras.layers.Dense(channels, activation='sigmoid', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(y)\n",
    "        y = x * y\n",
    "        z = tf.keras.layers.GlobalMaxPooling2D()(y)\n",
    "        z = tf.keras.layers.Dense(channels // 4, activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(z)\n",
    "        z = tf.keras.layers.Dense(channels, activation='sigmoid', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(z)\n",
    "        z = tf.keras.layers.Reshape((1, 1, channels))(z)\n",
    "        z = y * z\n",
    "        return z\n",
    "\n",
    "    # calculate number of layers with fused_mbconv\n",
    "    num_fused_layers = 2\n",
    "    num_layers = depth\n",
    "\n",
    "    # Calculate width multiplier for each block\n",
    "    widths = [1, 6, 6, 6]\n",
    "    width_multiplier = width\n",
    "\n",
    "    # Calculate depth multiplier for each block\n",
    "    depths = [1, 2, 2, 2]\n",
    "    depth_multiplier = depth\n",
    "\n",
    "    # Number of filters in each block\n",
    "    filters = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n",
    "\n",
    "    # First convolution layer\n",
    "    x = tf.keras.layers.Conv2D(round_filters(filters[0], width_multiplier, 8), kernel_size=3, strides=(2, 2),\n",
    "                               padding='same', use_bias=False)(input_tensor)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = swish(x)\n",
    "\n",
    "    # Blocks\n",
    "    num_layers_remaining = num_layers\n",
    "    for i in range(1, len(filters) - 1):\n",
    "        num_layers_block = round_repeats(num_layers_remaining, depth_multiplier)\n",
    "        num_layers_remaining -= num_layers_block\n",
    "\n",
    "        # use fused_mbconv_block for the first two blocks\n",
    "        if i <= num_fused_layers:\n",
    "            x = fused_mbconv_block(x, round_filters(filters[i], width_multiplier, 8),\n",
    "                                   round_filters(filters[i + 1], width_multiplier, 8),\n",
    "                                   strides=(1 if i == 1 else 2))\n",
    "        # use mbconv_block for the remaining blocks\n",
    "        else:\n",
    "            x = mbconv_block(x, round_filters(filters[i], width_multiplier, 8),\n",
    "                             round_filters(filters[i + 1], width_multiplier, 8),\n",
    "                             strides=(1 if i == 1 else 2))\n",
    "\n",
    "        # integrate CBAM block after every other block\n",
    "        if i % 2 == 0:\n",
    "            x = cbam_block(x)\n",
    "\n",
    "    # Last convolution layer\n",
    "    x = tf.keras.layers.Conv2D(round_filters(filters[-2], width_multiplier, 8), kernel_size=1, padding='same',\n",
    "                               use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = swish(x)\n",
    "\n",
    "    # Include top layers (classification head)\n",
    "    if include_top:\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "        x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(input_tensor, x)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "516c252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 14:07:36.316076: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29329 images belonging to 5 classes.\n",
      "Found 9164 images belonging to 5 classes.\n",
      "Epoch 1/30\n",
      "917/917 [==============================] - 962s 1s/step - loss: 0.6037 - accuracy: 0.7654\n",
      "Epoch 2/30\n",
      "917/917 [==============================] - 945s 1s/step - loss: 0.2407 - accuracy: 0.9130\n",
      "Epoch 3/30\n",
      "917/917 [==============================] - 956s 1s/step - loss: 0.1616 - accuracy: 0.9421\n",
      "Epoch 4/30\n",
      "917/917 [==============================] - 953s 1s/step - loss: 0.1275 - accuracy: 0.9552\n",
      "Epoch 5/30\n",
      "917/917 [==============================] - 966s 1s/step - loss: 0.1018 - accuracy: 0.9643\n",
      "Epoch 6/30\n",
      "917/917 [==============================] - 943s 1s/step - loss: 0.0820 - accuracy: 0.9705\n",
      "Epoch 7/30\n",
      "917/917 [==============================] - 952s 1s/step - loss: 0.0801 - accuracy: 0.9730\n",
      "Epoch 8/30\n",
      "917/917 [==============================] - 957s 1s/step - loss: 0.0575 - accuracy: 0.9804\n",
      "Epoch 9/30\n",
      "917/917 [==============================] - 925s 1s/step - loss: 0.0580 - accuracy: 0.9798\n",
      "Epoch 10/30\n",
      "917/917 [==============================] - 966s 1s/step - loss: 0.0543 - accuracy: 0.9804\n",
      "Epoch 11/30\n",
      "917/917 [==============================] - 943s 1s/step - loss: 0.0488 - accuracy: 0.9834\n",
      "Epoch 12/30\n",
      "917/917 [==============================] - 942s 1s/step - loss: 0.0439 - accuracy: 0.9854\n",
      "Epoch 13/30\n",
      "917/917 [==============================] - 957s 1s/step - loss: 0.0381 - accuracy: 0.9870\n",
      "Epoch 14/30\n",
      "917/917 [==============================] - 940s 1s/step - loss: 0.0390 - accuracy: 0.9862\n",
      "Epoch 15/30\n",
      "917/917 [==============================] - 946s 1s/step - loss: 0.0349 - accuracy: 0.9877\n",
      "Epoch 16/30\n",
      "917/917 [==============================] - 950s 1s/step - loss: 0.0286 - accuracy: 0.9900\n",
      "Epoch 17/30\n",
      "917/917 [==============================] - 948s 1s/step - loss: 0.0346 - accuracy: 0.9885\n",
      "Epoch 18/30\n",
      "917/917 [==============================] - 951s 1s/step - loss: 0.0263 - accuracy: 0.9914\n",
      "Epoch 19/30\n",
      "917/917 [==============================] - 951s 1s/step - loss: 0.0269 - accuracy: 0.9918\n",
      "Epoch 20/30\n",
      "917/917 [==============================] - 964s 1s/step - loss: 0.0282 - accuracy: 0.9905\n",
      "Epoch 21/30\n",
      "917/917 [==============================] - 952s 1s/step - loss: 0.0259 - accuracy: 0.9912\n",
      "Epoch 22/30\n",
      "917/917 [==============================] - 955s 1s/step - loss: 0.0209 - accuracy: 0.9928\n",
      "Epoch 23/30\n",
      "917/917 [==============================] - 954s 1s/step - loss: 0.0232 - accuracy: 0.9922\n",
      "Epoch 24/30\n",
      "917/917 [==============================] - 959s 1s/step - loss: 0.0189 - accuracy: 0.9938\n",
      "Epoch 25/30\n",
      "917/917 [==============================] - 984s 1s/step - loss: 0.0234 - accuracy: 0.9924\n",
      "Epoch 26/30\n",
      "917/917 [==============================] - 969s 1s/step - loss: 0.0164 - accuracy: 0.9943\n",
      "Epoch 27/30\n",
      "917/917 [==============================] - 973s 1s/step - loss: 0.0223 - accuracy: 0.9921\n",
      "Epoch 28/30\n",
      "917/917 [==============================] - 1098s 1s/step - loss: 0.0156 - accuracy: 0.9946\n",
      "Epoch 29/30\n",
      "917/917 [==============================] - 1084s 1s/step - loss: 0.0193 - accuracy: 0.9933\n",
      "Epoch 30/30\n",
      "917/917 [==============================] - 1044s 1s/step - loss: 0.0146 - accuracy: 0.9949\n",
      "287/287 [==============================] - 81s 279ms/step - loss: 0.0459 - accuracy: 0.9868\n",
      "Test accuracy: 0.9867961406707764\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define data generators for training and validation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "resolution = 224\n",
    "num_epochs = 30\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "train_dir = '/Users/hemalatha/Downloads/datasetB/train'\n",
    "test_dir = '/Users/hemalatha/Downloads/datasetB/test'\n",
    "\n",
    "# Define model hyperparameters\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 5\n",
    "dropout_rate = 0.2\n",
    "width = 1\n",
    "depth = 1.0\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "# Instantiate model\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "model = efficient_net(inputs, resolution=input_shape[0], depth=depth, width=width, num_classes=num_classes, dropout_rate=dropout_rate, include_top=True)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(resolution, resolution),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(resolution, resolution),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print('Test accuracy:', test_accuracy)\n",
    "\n",
    "# Save the model\n",
    "model.save('efficientnet_with_cbam_fuused.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0b3e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 21:43:54.352919: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5ed6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
